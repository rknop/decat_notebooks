{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "034e4508-f752-45a4-a225-659c78b4e871",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import psycopg2.extras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5594e2-f476-43d4-b224-0bdf2c07a8b6",
   "metadata": {
    "tags": []
   },
   "source": [
    "The galactic pipeline works as follows.  On designated \"reference\" images— right now I just have one per filter— it finds all sources using Eddie Schlafly's crowdsource algorithm, and saves them to the galsources table in the database.\n",
    "\n",
    "Then, for every other image (call them \"search\" images), it will run through the same reduction procedure.  It finds sources but does _not_ save them, instead just using them for astrometric and (sort of) photometric calibration.  After that, it reads all the sources from the reference image (of the relevant filter) from the database, and uses the \"force fit\" version of crowdsource to force there to be sources at all the same positions on the search image as they were on the ref image.  Because I noticed ~10% variations across the chip in the comparison between source and ref, I do a correction to the source magnitudes so that in bulk they match the ref magnitudes; that correction is a 4th-order chebyshev polynomnial in magnituide difference as a function of x and y across the image.  These corrected magnitudes for all of the sources that had >0 flux on the search image are saved to the database.  What this means is that the zeropoint saved in the database for the image is only an approximation.  We're more interested in relative photometry than absolute photometry, so I've calibrated the search image to the reference image.  The real photometric system is defined by the reference image, but then the zeropoint of the reference image should give you absolute calibration to within 10% or 20%.\n",
    "\n",
    "Finally, the pipeline looks at all of the sources in the search image for magnitude differences from the ref image.  Right now it finds a __lot__.  I do a few things.  First, when saving the catalog of the search image, I enforce an \"uncertainty floor\" of 0.01 magnitudes.  I don't believe that crowdsource can be trusted to better than this, even though it often quotes sub-0.01 magnitude uncertainties.  (It's probably not to better than 2%, in fact.)  There's also issues of how damn difficult it is to adequately subtract the sky in crowded fields.  I stopped using crowdsources' sky subtraction, and instead went with the Bijaoui algorithm (done in a 20x10 tiles to which a smooth background is fit), as I was getting better results with that.  Second, when I do the correction fit, I look at the χ²/ν value, and expand the uncertainties in the search image by a factor that will make the χ²/ν value go to 1.  (So far, typically, this has been a factor of a few.)  Finally, I do a 15σ cut on the magnitude difference, which sounds high, but the number of variables was overwhelming without that.  We can still tweak this pipeline if we don't like this.\n",
    "\n",
    "We still get a lot of variables.  However, many of them will be \"one-offs\"; that is, the result of an image artifact or something like that.  We'll want to focus more on the objects that are detected multiple times as differnt from the ref image.  One flaw in the pipeline right now is that an artifact in the _ref_ image will cause something to be detected multiple times.  I want to think about how to deal with that.  (Possiblities include: using mutiple ref images (all photometrically calibrated to one of them), stacked ref image with outlier rejection.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14b76b5-f902-42de-ab9d-f2c590a9e4a5",
   "metadata": {},
   "source": [
    "All of the tables for the galactic pipeline start with \"gal\"; the relevant ones are:\n",
    "* galexposures — each full 62-chip exposure downloaded from the NOIRLab data archive\n",
    "* galimages — one record for each chip of each exposure; galexposure_id points to the galexposures table\n",
    "* galsources — this is the __GIANT__ table (as in 10⁷ rows per exposure).  Sources detected on images.  galimage_id points to the galimages table.\n",
    "* galvarobjs — variable objects detectected where the galsources entry for an image was significantly different from the galsources entry for that same object for the relevant reference image.  (The galimages field \"reference\" tells you which image was used as a reference for a given search image\n",
    "\n",
    "I'm hoping that the q3c extension will make searching the ginormous galsources table by ra/dec relatively quick.  This does mean I have to regularly run a very slow \"cluster\" process to make the q3c index effective, which seems to lock up the galsources table while I'm doing it.  We may decide that saving all the sources from every image is too much for the database, but it would be really nice if we could keep that, as it means that when a variable object is detected, all of the photometry that we've succesfully grabbed for that object is already right there in the database."
   ]
  },
  {
   "cell_type": "raw",
   "id": "e37548d1-59d6-421d-827a-d2cadff91f93",
   "metadata": {},
   "source": [
    "Right now, I'm only working in \"development\" mode, which means that a smallish number of images have been loaded into the decat_dev database, and they may get deleted or munged about as I keep working.  However, if you want to look at the sorts of things that are coming up, this is the database to look at."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588bc83c-8455-4d16-882c-b14b3d714f84",
   "metadata": {},
   "source": [
    "Here's a query that will get counts of how many times a given object was detected as variable (i.e. different from the ref).  The \"refsource_id\" will be the same for the same objects.  (This is _within a filter_.  The same star in g and and r will have different refsource ids.  Cross-filter identification will require searches by RA/DEC, and then there will be blending issues if the photometry on the g and r refs didn't deblend the objects the same way!  The galaxy has too many stars.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08667942-8723-4548-8ccf-18d81a9bf145",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = psycopg2.connect(\"dbname='decat_dev' user='mgraham' password='PutYourPasswordHere' host='decatdb.lbl.gov'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7109e03b-edcf-488b-b7f1-097572347c68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeated Detections  Number of Objects\n",
      "           9                     63\n",
      "           8                    401\n",
      "           7                    496\n",
      "           6                   1850\n",
      "           5                   2520\n",
      "           4                   1407\n",
      "           3                   1930\n",
      "           2                   3437\n",
      "           1                  27786\n"
     ]
    }
   ],
   "source": [
    "cursor = db.cursor( cursor_factory = psycopg2.extras.DictCursor )\n",
    "query = ( \"SELECT num,COUNT(num) as count \"\n",
    "          \"FROM ( SELECT COUNT(v.id) as num \"\n",
    "                 \"FROM galvarobjs v \"\n",
    "                 \"GROUP BY refsource_id ) subq \"\n",
    "          \"GROUP BY num \"\n",
    "          \"ORDER BY num DESC\" )\n",
    "cursor.execute( query )\n",
    "print( \"Repeated Detections  Number of Objects\" )\n",
    "for row in cursor.fetchall():\n",
    "    print( f'    {row[\"num\"]:8d}               {row[\"count\"]:8d}' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3af6413-34a1-40d6-9d57-e8b35512c4fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
